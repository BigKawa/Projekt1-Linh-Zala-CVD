{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Run \"pip install kaggle\" \n",
    "\n",
    "2. Move \"kaggle.json\" to following Path /Users/linh/.kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing relevent libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from cleaning import *  # Import all functions from cleaning\n",
    "import zipfile\n",
    "import kaggle\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi  # Import Kaggle Api\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Page Token = CfDJ8KWOACvMaNFPiIJ818QpJK0tIcIi4b9pBTxeEziVX7ptMPlnU4h0X1EtUMxfjGNjyOgAmlAxitLs3BNhpTo0UwI\n",
      "    id  ref                                              title                            subtitle                                                                                                                                                                                                                                                       author                                  \n",
      "------  -----------------------------------------------  -------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  --------------------------------------  \n",
      "121027  metaresearch/llama-3.2                           Llama 3.2                        The Meta Llama 3.2 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction-tuned generative models in 1B and 3B sizes (text in/text out).                                                                        Meta                                    \n",
      "105694  adedapoadeniran/ai-qr-code-decoder-deeplearning  AI-QR-Code-Decoder-DeepLearning  Xception DL architecture trained on 2500 QR Codes v1 images of four digits numbers starting from 1002 to 9996                                                                                                                                                  Brainydaps                              \n",
      "  3301  google/gemma                                     Gemma                            Gemma is a family of lightweight, open models built from the research and technology that Google used to create the Gemini models.                                                                                                                             Google                                  \n",
      "105272  umeradnaan/yolo-v8                               YOLO-V8                          Remote Sensing Satellite                                                                                                                                                                                                                                       Shaik Barood Mohammed Umar Adnaan Faiz  \n",
      " 91102  metaresearch/llama-3.1                           Llama 3.1                        The Meta Llama 3.1 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction tuned generative models in 8B, 70B and 405B sizes (text in/text out).                                                                 Meta                                    \n",
      "121030  metaresearch/llama-3.2-vision                    Llama 3.2 Vision                 The Llama 3.2-Vision collection of multimodal large language models (LLMs) is a collection of pretrained and instruction-tuned image reasoning generative models in 11B and 90B sizes (text + images in / text out).                                           Meta                                    \n",
      "111013  google/datagemma-rig                             DataGemma RIG                    Fine-tuned Gemma model that harnesses the knowledge of Data Commons to enhance LLM factuality and reasoning.                                                                                                                                                   Google                                  \n",
      "  3533  keras/gemma                                      Gemma                            Keras implementation of the Gemma model. This Keras 3 implementation will run on JAX, TensorFlow and PyTorch.                                                                                                                                                  Keras                                   \n",
      "100857  metaresearch/segment-anything-2                  Segment Anything 2               Segment Anything Model 2 (SAM 2) is a foundation model towards solving promptable visual segmentation in images and videos.                                                                                                                                    Meta                                    \n",
      "111039  google/datagemma-rag                             DataGemma RAG                    Fine-tuned Gemma model that helps LLMs harness the knowledge of Data Commons to enhance factuality and reasoning.                                                                                                                                              Google                                  \n",
      "124592  metaresearch/llama-guard-3.2                     Llama Guard 3.2                  Llama Guard 3-1B is a fine-tuned Llama-3.2-1B pretrained model for content safety classification. Similar to previous versions, it can be used to classify content in both LLM inputs (prompt classification) and in LLM responses (response classification).  Meta                                    \n",
      "119502  abdullahmeda/stella-en-embedding-400m-v5         Stella EN Embedding 400M v5                                                                                                                                                                                                                                                                     Abdullah Meda                           \n",
      "107178  black-forest-labs/flux                           FLUX.1                           The FLUX.1 models are 12 billion parameter rectified flow transformers that generate images given a text prompt.                                                                                                                                               Black Forest Labs                       \n",
      "116117  madhuraatmarambhagat/images                      YOLO Algorithm                   Pretrained YOLO model                                                                                                                                                                                                                                          Madhura Atmaram Bhagat                  \n",
      "105384  collinstedham/lexie-1                            Lexie 1                          This is the best model so far! Experience the future of AI with this humanlike AI that is sure to be your best helper and friend. Lexie is ready to help with insanely powerful search, pdf and image capabilities, translation, and so much more!             Collin Stedham                          \n",
      "124593  metaresearch/llama-guard-vision-3.2              Llama Guard Vision 3.2           Llama Guard 3 Vision is a Llama-3.2-11B pretrained model, fine-tuned for content safety classification. Similar to previous versions [1-3], it can be used to safeguard content for both LLM inputs (prompt classification) and LLM responses.                 Meta                                    \n",
      "117041  faiqueali/facenet-tensorflow                     FaceNet | Tensorflow             Pretrained FaceNet model for face recognition and embedding generation, optimized for use in real-time applications                                                                                                                                            Faique Ali                              \n",
      "  2797  keras/efficientnetv2                             EfficientNetV2                   Instantiates the EfficientNetV2 architecture.                                                                                                                                                                                                                  Keras                                   \n",
      " 78150  keras/gemma2                                     Gemma 2                          Keras implementation of the Gemma 2 model. This Keras 3 implementation will run on JAX, TensorFlow and PyTorch.                                                                                                                                                Keras                                   \n",
      "123513  richolson/phi-3.5-mini-instruct                  Phi-3.5-mini-instruct                                                                                                                                                                                                                                                                           Rich Olson                              \n",
      "Dataset URL: https://www.kaggle.com/datasets/alexteboul/heart-disease-health-indicators-dataset\n"
     ]
    }
   ],
   "source": [
    "# Initiliaze API\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "api.model_list_cli()\n",
    "\n",
    "# Donwload Dataset via API unzipped\n",
    "api.dataset_download_files(dataset=\"alexteboul/heart-disease-health-indicators-dataset\", unzip=True)\n",
    "\n",
    "# Saving DataSets into DF\n",
    "usa_df = pd.read_csv(\"heart_disease_health_indicators_BRFSS2015.csv\")\n",
    "india_df = pd.read_csv(\"./Data/CVD_india_data_raw.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape norm tables from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# blood pressure\n",
    "url = \"https://en.wikipedia.org/wiki/Blood_pressure\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "table = soup.find(\"table\", class_=\"wikitable\")\n",
    "\n",
    "categories = []\n",
    "office_data = []\n",
    "relevant_data = False\n",
    "\n",
    "for row in table.find_all('tr'):\n",
    "    header_cells = row.find_all('th')\n",
    "    if header_cells and \"European Society of Cardiology\" in header_cells[0].get_text():\n",
    "        relevant_data = True\n",
    "        continue\n",
    "    if header_cells and \"European Society of Hypertension\" in header_cells[0].get_text():\n",
    "        relevant_data = False\n",
    "        break\n",
    "    if relevant_data:\n",
    "        data_cells = row.find_all('td')\n",
    "        if len(data_cells) > 1:  # Ensures we have enough columns\n",
    "            categories.append(data_cells[0].get_text(strip=True))\n",
    "            office_data.append(data_cells[1].get_text(strip=True))\n",
    "\n",
    "bp_df = pd.DataFrame({'Category': categories, 'Office': office_data})\n",
    "bp_thresh = int(bp_df[bp_df['Category'] == 'Non-elevated']['Office'].values[0].split(\"<\")[1])\n",
    "bp_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cholesterol\n",
    "url = \"https://en.wikipedia.org/wiki/Cholesterol\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "table = soup.find(\"table\", class_=\"wikitable\")\n",
    "rows = table.find(\"tbody\").find_all('tr')\n",
    "\n",
    "chol_data = []\n",
    "selected_rows = [1, 2, 3, 4]\n",
    "\n",
    "for i in selected_rows:\n",
    "    if i == 1:\n",
    "        cell = rows[i].find('th').get_text(strip=True)\n",
    "    else:\n",
    "        cell = rows[i].find('td').get_text(strip=True)\n",
    "    chol_data.append(cell)\n",
    "\n",
    "chol_data\n",
    "chol_thresh = int(chol_data[1].strip(\"< \"))\n",
    "chol_thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating new binary columns for blood pressure and cholesterol in India data which match the US data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n",
      "[0 1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientid</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>chestpain</th>\n",
       "      <th>restingBP</th>\n",
       "      <th>serumcholestrol</th>\n",
       "      <th>fastingbloodsugar</th>\n",
       "      <th>restingrelectro</th>\n",
       "      <th>maxheartrate</th>\n",
       "      <th>exerciseangia</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>noofmajorvessels</th>\n",
       "      <th>target</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103368</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>119250</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119372</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>133</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132514</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>295</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>146211</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patientid  age  gender  chestpain  restingBP  serumcholestrol  \\\n",
       "0     103368   53       1          2        171                0   \n",
       "1     119250   40       1          0         94              229   \n",
       "2     119372   49       1          2        133              142   \n",
       "3     132514   43       1          0        138              295   \n",
       "4     146211   31       1          1        199                0   \n",
       "\n",
       "   fastingbloodsugar  restingrelectro  maxheartrate  exerciseangia  oldpeak  \\\n",
       "0                  0                1           147              0      5.3   \n",
       "1                  0                1           115              0      3.7   \n",
       "2                  0                0           202              1      5.0   \n",
       "3                  1                1           153              0      3.2   \n",
       "4                  0                2           136              0      5.3   \n",
       "\n",
       "   slope  noofmajorvessels  target  HighBP  HighChol  \n",
       "0      3                 3       1       1         0  \n",
       "1      1                 1       0       0         1  \n",
       "2      1                 0       0       1         0  \n",
       "3      2                 2       1       1         1  \n",
       "4      3                 2       1       1         0  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "india_df[\"HighBP\"] = india_df[\"restingBP\"].apply(lambda x: 1 if x >= bp_thresh else 0)\n",
    "print(india_df[\"HighBP\"].unique())\n",
    "\n",
    "india_df[\"HighChol\"] = india_df[\"serumcholestrol\"].apply(lambda x: 1 if x >= chol_thresh else 0)\n",
    "print(india_df[\"HighChol\"].unique())\n",
    "\n",
    "india_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no missings in patientid\n",
      "no missings in age\n",
      "no missings in gender\n",
      "no missings in chestpain\n",
      "no missings in restingBP\n",
      "no missings in serumcholestrol\n",
      "no missings in fastingbloodsugar\n",
      "no missings in restingrelectro\n",
      "no missings in maxheartrate\n",
      "no missings in exerciseangia\n",
      "no missings in oldpeak\n",
      "no missings in slope\n",
      "no missings in noofmajorvessels\n",
      "no missings in target\n",
      "no missings in HighBP\n",
      "no missings in HighChol\n",
      "\n",
      "\n",
      "# of unique vals in patientid: 1000\n",
      "\n",
      "\n",
      "# of unique vals in age: 61\n",
      "\n",
      "\n",
      "# of unique vals in gender: 2\n",
      "unique vals in gender: [0, 1]\n",
      "\n",
      "\n",
      "# of unique vals in chestpain: 4\n",
      "unique vals in chestpain: [0, 1, 2, 3]\n",
      "\n",
      "\n",
      "# of unique vals in restingBP: 95\n",
      "\n",
      "\n",
      "# of unique vals in serumcholestrol: 344\n",
      "\n",
      "\n",
      "# of unique vals in fastingbloodsugar: 2\n",
      "unique vals in fastingbloodsugar: [0, 1]\n",
      "\n",
      "\n",
      "# of unique vals in restingrelectro: 3\n",
      "unique vals in restingrelectro: [0, 1, 2]\n",
      "\n",
      "\n",
      "# of unique vals in maxheartrate: 129\n",
      "\n",
      "\n",
      "# of unique vals in exerciseangia: 2\n",
      "unique vals in exerciseangia: [0, 1]\n",
      "\n",
      "\n",
      "# of unique vals in oldpeak: 63\n",
      "\n",
      "\n",
      "# of unique vals in slope: 4\n",
      "unique vals in slope: [0, 1, 2, 3]\n",
      "\n",
      "\n",
      "# of unique vals in noofmajorvessels: 4\n",
      "unique vals in noofmajorvessels: [0, 1, 2, 3]\n",
      "\n",
      "\n",
      "# of unique vals in target: 2\n",
      "unique vals in target: [0, 1]\n",
      "\n",
      "\n",
      "# of unique vals in HighBP: 2\n",
      "unique vals in HighBP: [0, 1]\n",
      "\n",
      "\n",
      "# of unique vals in HighChol: 2\n",
      "unique vals in HighChol: [0, 1]\n",
      "no missings in HeartDiseaseorAttack\n",
      "no missings in HighBP\n",
      "no missings in HighChol\n",
      "no missings in CholCheck\n",
      "no missings in BMI\n",
      "no missings in Smoker\n",
      "no missings in Stroke\n",
      "no missings in Diabetes\n",
      "no missings in PhysActivity\n",
      "no missings in Fruits\n",
      "no missings in Veggies\n",
      "no missings in HvyAlcoholConsump\n",
      "no missings in AnyHealthcare\n",
      "no missings in NoDocbcCost\n",
      "no missings in GenHlth\n",
      "no missings in MentHlth\n",
      "no missings in PhysHlth\n",
      "no missings in DiffWalk\n",
      "no missings in Sex\n",
      "no missings in Age\n",
      "no missings in Education\n",
      "no missings in Income\n",
      "\n",
      "\n",
      "# of unique vals in HeartDiseaseorAttack: 2\n",
      "unique vals in HeartDiseaseorAttack: [0.0, 1.0]\n",
      "\n",
      "\n",
      "# of unique vals in HighBP: 2\n",
      "unique vals in HighBP: [0.0, 1.0]\n",
      "\n",
      "\n",
      "# of unique vals in HighChol: 2\n",
      "unique vals in HighChol: [0.0, 1.0]\n",
      "\n",
      "\n",
      "# of unique vals in CholCheck: 2\n",
      "unique vals in CholCheck: [0.0, 1.0]\n",
      "\n",
      "\n",
      "# of unique vals in BMI: 84\n",
      "\n",
      "\n",
      "# of unique vals in Smoker: 2\n",
      "unique vals in Smoker: [0.0, 1.0]\n",
      "\n",
      "\n",
      "# of unique vals in Stroke: 2\n",
      "unique vals in Stroke: [0.0, 1.0]\n",
      "\n",
      "\n",
      "# of unique vals in Diabetes: 3\n",
      "unique vals in Diabetes: [0.0, 1.0, 2.0]\n",
      "\n",
      "\n",
      "# of unique vals in PhysActivity: 2\n",
      "unique vals in PhysActivity: [0.0, 1.0]\n",
      "\n",
      "\n",
      "# of unique vals in Fruits: 2\n",
      "unique vals in Fruits: [0.0, 1.0]\n",
      "\n",
      "\n",
      "# of unique vals in Veggies: 2\n",
      "unique vals in Veggies: [0.0, 1.0]\n",
      "\n",
      "\n",
      "# of unique vals in HvyAlcoholConsump: 2\n",
      "unique vals in HvyAlcoholConsump: [0.0, 1.0]\n",
      "\n",
      "\n",
      "# of unique vals in AnyHealthcare: 2\n",
      "unique vals in AnyHealthcare: [0.0, 1.0]\n",
      "\n",
      "\n",
      "# of unique vals in NoDocbcCost: 2\n",
      "unique vals in NoDocbcCost: [0.0, 1.0]\n",
      "\n",
      "\n",
      "# of unique vals in GenHlth: 5\n",
      "unique vals in GenHlth: [1.0, 2.0, 3.0, 4.0, 5.0]\n",
      "\n",
      "\n",
      "# of unique vals in MentHlth: 31\n",
      "\n",
      "\n",
      "# of unique vals in PhysHlth: 31\n",
      "\n",
      "\n",
      "# of unique vals in DiffWalk: 2\n",
      "unique vals in DiffWalk: [0.0, 1.0]\n",
      "\n",
      "\n",
      "# of unique vals in Sex: 2\n",
      "unique vals in Sex: [0.0, 1.0]\n",
      "\n",
      "\n",
      "# of unique vals in Age: 13\n",
      "\n",
      "\n",
      "# of unique vals in Education: 6\n",
      "unique vals in Education: [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]\n",
      "\n",
      "\n",
      "# of unique vals in Income: 8\n",
      "unique vals in Income: [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0]\n"
     ]
    }
   ],
   "source": [
    "# apply functions for cleaning check\n",
    "check_nan(india_df)\n",
    "check_unique(india_df)\n",
    "check_nan(usa_df)\n",
    "check_unique(usa_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synchronize matching columns\n",
    "usa_df.columns = usa_df.columns.str.lower()\n",
    "india_df.columns = india_df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aligning Dtypes\n",
    "usa_df = usa_df.apply(lambda x:x.astype(int))\n",
    "india_df = india_df.apply(lambda x:x.astype(int, errors= \"ignore\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking and konsolodate the columns\n",
    "# Renaming India columns\n",
    "india_df = india_df.rename(columns={\"target\":\"cvd\"})\n",
    "\n",
    "# Renaming usa columns\n",
    "usa_df = usa_df.rename(columns={\"sex\":\"gender\"})\n",
    "usa_df = usa_df.rename(columns={\"heartdiseaseorattack\":\"cvd\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assgning gender \n",
    "# sacrificing performance for readibility in this case int to object\n",
    "gender = {\n",
    "    1:\"m\",\n",
    "    0:\"f\"\n",
    "}\n",
    "india_df[\"gender\"] = india_df[\"gender\"].map(gender)  \n",
    "usa_df[\"gender\"] = usa_df[\"gender\"].map(gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add country column to both dataframes\n",
    "india_df['country'] = 'india'\n",
    "usa_df['country'] = 'usa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country  age\n",
      "india    1       8.0\n",
      "         2       9.0\n",
      "         3       8.0\n",
      "         4       8.0\n",
      "         5       8.0\n",
      "         6       9.0\n",
      "         7       8.0\n",
      "         8       8.0\n",
      "         9       8.0\n",
      "         10      7.0\n",
      "         11      8.0\n",
      "         12      8.0\n",
      "         13      3.0\n",
      "usa      1       2.0\n",
      "         2       3.0\n",
      "         3       4.0\n",
      "         4       5.0\n",
      "         5       6.0\n",
      "         6       8.0\n",
      "         7      10.0\n",
      "         8      12.0\n",
      "         9      13.0\n",
      "         10     13.0\n",
      "         11      9.0\n",
      "         12      6.0\n",
      "         13      7.0\n",
      "Name: proportion, dtype: float64\n",
      "   age gender  cvd  highbp  highchol country\n",
      "0    7      m    1       1         0   india\n",
      "1    5      m    0       0         1   india\n",
      "2    7      m    0       1         0   india\n",
      "3    5      m    1       1         1   india\n",
      "4    3      m    1       1         0   india\n"
     ]
    }
   ],
   "source": [
    "# Concantenate the DataFrames\n",
    "merged = pd.concat([india_df, usa_df], axis=0, ignore_index=True)\n",
    "# find common cols\n",
    "common_columns = india_df.columns.intersection(usa_df.columns)\n",
    "# drop all columns except those with data in both samples: age, gender, heartdiseaseorattack, highbp, highchol\n",
    "merged = merged[common_columns]\n",
    "\n",
    "# cetegorize india age\n",
    "merged.loc[merged['country'] == 'india', 'age'] = pd.cut(merged.loc[merged['country'] == 'india', 'age'],\n",
    "                                                               bins=range(18, 85, 5),\n",
    "                                                               labels=range(1, 14),\n",
    "                                                               right=True).astype(int)\n",
    "\n",
    "grouped = (merged.groupby(\"country\")[\"age\"].value_counts(normalize=True).sort_index() * 100).round()\n",
    "\n",
    "# Print the percentage of each age value for India and USA separately\n",
    "print(grouped)\n",
    "print(merged.head())\n",
    "\n",
    "# save\n",
    "merged.to_csv(\"./Data/merged_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis on combined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prevalence by Country:\n",
      "           highbp   highchol        cvd\n",
      "country                                \n",
      "india    89.40000  82.400000  58.000000\n",
      "usa      42.90011  42.412094   9.418559\n",
      "\n",
      "H1: The prevalence of high blood pressure is higher in the US compared to India: False\n",
      "H2: The prevalence of high cholesterol is higher in the US compared to India: False\n",
      "H3: The prevalence of CVD is higher in the US compared to India: False\n"
     ]
    }
   ],
   "source": [
    "# H1: The prevalence of high blood pressure is higher in the USA compared to India\n",
    "# H2: The prevalence of high cholesterol is higher in the USA compared to India\n",
    "# H3: The prevalence of heart disease is higher in the USA compared to India\n",
    "grouped = merged.groupby(\"country\")[[\"highbp\", \"highchol\", \"cvd\"]].mean() * 100\n",
    "\n",
    "print(\"Prevalence by Country:\")\n",
    "print(grouped)\n",
    "print()\n",
    "\n",
    "# Logical statements to compare the USA and India for each condition\n",
    "print(\"H1: The prevalence of high blood pressure is higher in the US compared to India:\", grouped.loc[\"usa\", \"highbp\"] > grouped.loc[\"india\", \"highbp\"])\n",
    "print(\"H2: The prevalence of high cholesterol is higher in the US compared to India:\", grouped.loc[\"usa\", \"highchol\"] > grouped.loc[\"india\", \"highchol\"])\n",
    "print(\"H3: The prevalence of CVD is higher in the US compared to India:\", grouped.loc[\"usa\", \"cvd\"] > grouped.loc[\"india\", \"cvd\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis on US sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVD prevalence among smokers: 13.17%\n",
      "CVD prevalence among non-smokers: 6.44%\n",
      "H4: The prevalence of CVD is higher among smokers than non-smokers: True\n"
     ]
    }
   ],
   "source": [
    "# H4: The prevalence of cvd is higher among smokers than non-smokers\n",
    "smoker = usa_df[usa_df[\"smoker\"] == 1]\n",
    "non_smoker = usa_df[usa_df[\"smoker\"] == 0]\n",
    "\n",
    "# Calculating the percentage of individuals with heart disease in each group\n",
    "cvd_smoker = (smoker[\"cvd\"].mean()) * 100\n",
    "cvd_non_smoker = (non_smoker[\"cvd\"].mean()) * 100\n",
    "\n",
    "print(f\"CVD prevalence among smokers: {cvd_smoker:.2f}%\")\n",
    "print(f\"CVD prevalence among non-smokers: {cvd_non_smoker:.2f}%\")\n",
    "print(\"H4: The prevalence of CVD is higher among smokers than non-smokers:\" , cvd_smoker > cvd_non_smoker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage with heart disease among those with high BP: 16.47%\n",
      "Percentage with heart disease among those without high BP: 4.12%\n",
      "H5: The prevalence of CVD is higher among individuals with high BP: True\n"
     ]
    }
   ],
   "source": [
    "# H5: The prevalence of cvd is higher among those with high BP\n",
    "high_bp = usa_df[usa_df[\"highbp\"] == 1]\n",
    "no_high_bp = usa_df[usa_df[\"highbp\"] == 0]\n",
    "\n",
    "# Calculating the percentage of individuals with heart disease in each group\n",
    "heart_disease_high_bp = (high_bp[\"cvd\"].mean()) * 100\n",
    "heart_disease_no_high_bp = (no_high_bp[\"cvd\"].mean()) * 100\n",
    "\n",
    "print(f\"Percentage with heart disease among those with high BP: {heart_disease_high_bp:.2f}%\")\n",
    "print(f\"Percentage with heart disease among those without high BP: {heart_disease_no_high_bp:.2f}%\")\n",
    "print(\"H5: The prevalence of CVD is higher among individuals with high BP:\" , heart_disease_high_bp > heart_disease_no_high_bp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H6: The prevalence of cvd is higher among those with high chol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining relevant Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
