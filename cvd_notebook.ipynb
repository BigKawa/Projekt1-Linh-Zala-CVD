{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Run \"pip install kaggle\" \n",
    "\n",
    "2. Move \"kaggle.json\" to following Path /Users/linh/.kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing relevent libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from cleaning import *  # Import all functions from cleaning\n",
    "import kaggle\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi  # Import Kaggle Api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /Users/linh/.kaggle/kaggle.json'\n",
      "Next Page Token = CfDJ8KWOACvMaNFPiIJ818QpJK2EhOzcH3mkfyB8U13PPT1BpFRzZopUOJSQ02QvSIkfqoY2CEV7xqyZoDrBwVOG3E0\n",
      "    id  ref                                              title                            subtitle                                                                                                                                                                                                                                                       author                                  \n",
      "------  -----------------------------------------------  -------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  --------------------------------------  \n",
      "121027  metaresearch/llama-3.2                           Llama 3.2                        The Meta Llama 3.2 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction-tuned generative models in 1B and 3B sizes (text in/text out).                                                                        Meta                                    \n",
      "105694  adedapoadeniran/ai-qr-code-decoder-deeplearning  AI-QR-Code-Decoder-DeepLearning  Xception DL architecture trained on 2500 QR Codes v1 images of four digits numbers starting from 1002 to 9996                                                                                                                                                  Brainydaps                              \n",
      "  3301  google/gemma                                     Gemma                            Gemma is a family of lightweight, open models built from the research and technology that Google used to create the Gemini models.                                                                                                                             Google                                  \n",
      "105272  umeradnaan/yolo-v8                               YOLO-V8                          Remote Sensing Satellite                                                                                                                                                                                                                                       Shaik Barood Mohammed Umar Adnaan Faiz  \n",
      " 91102  metaresearch/llama-3.1                           Llama 3.1                        The Meta Llama 3.1 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction tuned generative models in 8B, 70B and 405B sizes (text in/text out).                                                                 Meta                                    \n",
      "121030  metaresearch/llama-3.2-vision                    Llama 3.2 Vision                 The Llama 3.2-Vision collection of multimodal large language models (LLMs) is a collection of pretrained and instruction-tuned image reasoning generative models in 11B and 90B sizes (text + images in / text out).                                           Meta                                    \n",
      "111013  google/datagemma-rig                             DataGemma RIG                    Fine-tuned Gemma model that harnesses the knowledge of Data Commons to enhance LLM factuality and reasoning.                                                                                                                                                   Google                                  \n",
      "  3533  keras/gemma                                      Gemma                            Keras implementation of the Gemma model. This Keras 3 implementation will run on JAX, TensorFlow and PyTorch.                                                                                                                                                  Keras                                   \n",
      "105384  collinstedham/lexie-1                            Lexie 1                          This is the best model so far! Experience the future of AI with this humanlike AI that is sure to be your best helper and friend. Lexie is ready to help with insanely powerful search, pdf and image capabilities, translation, and so much more!             Collin Stedham                          \n",
      "100857  metaresearch/segment-anything-2                  Segment Anything 2               Segment Anything Model 2 (SAM 2) is a foundation model towards solving promptable visual segmentation in images and videos.                                                                                                                                    Meta                                    \n",
      "111039  google/datagemma-rag                             DataGemma RAG                    Fine-tuned Gemma model that helps LLMs harness the knowledge of Data Commons to enhance factuality and reasoning.                                                                                                                                              Google                                  \n",
      "107178  black-forest-labs/flux                           FLUX.1                           The FLUX.1 models are 12 billion parameter rectified flow transformers that generate images given a text prompt.                                                                                                                                               Black Forest Labs                       \n",
      "124592  metaresearch/llama-guard-3.2                     Llama Guard 3.2                  Llama Guard 3-1B is a fine-tuned Llama-3.2-1B pretrained model for content safety classification. Similar to previous versions, it can be used to classify content in both LLM inputs (prompt classification) and in LLM responses (response classification).  Meta                                    \n",
      "116117  madhuraatmarambhagat/images                      YOLO Algorithm                   Pretrained YOLO model                                                                                                                                                                                                                                          Madhura Atmaram Bhagat                  \n",
      "119502  abdullahmeda/stella-en-embedding-400m-v5         Stella EN Embedding 400M v5                                                                                                                                                                                                                                                                     Abdullah Meda                           \n",
      "124593  metaresearch/llama-guard-vision-3.2              Llama Guard Vision 3.2           Llama Guard 3 Vision is a Llama-3.2-11B pretrained model, fine-tuned for content safety classification. Similar to previous versions [1-3], it can be used to safeguard content for both LLM inputs (prompt classification) and LLM responses.                 Meta                                    \n",
      "  2797  keras/efficientnetv2                             EfficientNetV2                   Instantiates the EfficientNetV2 architecture.                                                                                                                                                                                                                  Keras                                   \n",
      " 78150  keras/gemma2                                     Gemma 2                          Keras implementation of the Gemma 2 model. This Keras 3 implementation will run on JAX, TensorFlow and PyTorch.                                                                                                                                                Keras                                   \n",
      " 39106  metaresearch/llama-3                             Llama 3                          Llama 3 is a collection of pretrained and fine-tuned generative text models ranging in scale from 8 billion to 70 billion parameters                                                                                                                           Meta                                    \n",
      " 76277  google/gemma-2                                   Gemma 2                          Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models.                                                                                                      Google                                  \n"
     ]
    }
   ],
   "source": [
    "# Initiliaze API\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "api.model_list_cli()\n",
    "\n",
    "# Next Page Token = [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving CSV into DF\n",
    "india_df = pd.read_csv(\"./Data/Cardiovascular_Disease_Dataset.csv\")\n",
    "india_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.kaggle.com/datasets/alexteboul/heart-disease-health-indicators-dataset'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Working through API and Call new Data per api \n",
    "\"https://www.kaggle.com/datasets/alexteboul/heart-disease-health-indicators-dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking and konsolodate the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concantenate the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Hypothesis and relevant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant Liberaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining relevant Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
